
title:Report1
author: "Olatunde Kudus Bakare"
date: 2025-10-12
  type: default
format:
  html:
    toc: true
    number-sections:true
    code-fold: false
execute:
  echo: true
  warning: false
  message: false
    
# Report1.R
# A Comprehensive Genetic Evaluation: Comparison between Standard Genetic Protein Sequencing DNA codes and randomly generated Protein Sequencing DNA codes. Plus a Stimulated Annealing computational experiment that shows the SGC can be improved.
# Author: Olatunde Kudus Bakare
# Date: 2025-11-12
###############################################################

```{r}
# ==================== 1. Packages ================================
suppressPackageStartupMessages({
  library(jsonlite)
  library(tidyverse)
  library(readxl)
  library(cluster)
  library(factoextra)
  library(ggplot2)
  library(ggrepel)
  library(dplyr)
  library(tibble)
  library(stringr)
})
```
```{r}
# ==================== 2. Set File Paths ================================
# Keep data_path as the single root; do NOT concatenate it with another absolute path.
# Use file.path() so separators are correct on any OS.

data_path <- "~/Documents/CSB195 forked"   # <- adjust only this if needed

aa_prop_path      <- file.path(data_path, "dat", "aa_prop.json")              # can be .json OR .csv
aa_feature_path   <- file.path(data_path, "dat", "aaFeatureSpace.4.1.Rds")
aa_sim_path       <- file.path(data_path, "dat", "aaSim.4.1.Rds")
sgc_path          <- file.path(data_path, "dat", "SGC.csv")
breimann1_path    <- file.path(data_path, "dat", "Breimann_2024_Supplementary_Table_1.xlsx")
breimann2_path    <- file.path(data_path, "dat", "Breimann_2024_Supplementary_Table_3.xlsx")
```
```{r}
# ==================== 3. Helpers ================================

# Auto-detect JSON vs CSV by first non-space character, and read accordingly.
read_aa_table <- function(path) {
  txt <- readr::read_file(path)
  txt_trim <- sub("^\\s+", "", txt)
  if (nzchar(txt_trim) && (startsWith(txt_trim, "[") || startsWith(txt_trim, "{"))) {
    as_tibble(jsonlite::fromJSON(txt, flatten = TRUE))
  } else {
    suppressMessages(readr::read_csv(path, show_col_types = FALSE))
  }
}

# Build a robust AA property table that exposes 1-letter ('A'), 3-letter ('Aaa') and full name ('AminoAcid').
# Works whether input cols are one/three/name OR AminoAcid/Aaa/A.
normalize_aa_table <- function(df) {
  cols <- names(df)

  # infer columns
  A_col   <- dplyr::case_when(
    "A" %in% cols ~ "A",
    "one" %in% cols ~ "one",
    TRUE ~ NA_character_
  )
  Aaa_col <- dplyr::case_when(
    "Aaa" %in% cols ~ "Aaa",
    "three" %in% cols ~ "three",
    TRUE ~ NA_character_
  )
  Amino_col <- dplyr::case_when(
    "AminoAcid" %in% cols ~ "AminoAcid",
    "name" %in% cols ~ "name",
    TRUE ~ NA_character_
  )

  # at least one identifier must exist
  if (all(is.na(c(A_col, Aaa_col, Amino_col)))) {
    stop("aa_prop does not contain recognizable identifier columns (A/Aaa/AminoAcid or one/three/name).", call. = FALSE)
  }

  out <- df

  # Create unified columns, preserving originals
  if (!is.na(A_col))    out <- out |> mutate(A = toupper(.data[[A_col]])) else out <- out |> mutate(A = NA_character_)
  if (!is.na(Aaa_col))  out <- out |> mutate(Aaa = toupper(.data[[Aaa_col]])) else out <- out |> mutate(Aaa = NA_character_)
  if (!is.na(Amino_col)) {
    # Title-case for readability, keep STOP upper
    out <- out |> mutate(
      AminoAcid = ifelse(toupper(.data[[Amino_col]]) == "STOP",
                         "STOP",
                         stringr::str_to_title(.data[[Amino_col]]))
    )
  } else {
    out <- out |> mutate(AminoAcid = NA_character_)
  }

  # Final normalized table
  out
}
```
```{r}
# Choose the best identifier column (A, Aaa, or AminoAcid) that matches a set of labels.
pick_id_column_for_dist <- function(labels, sgc) {
  labels <- toupper(labels)

  # Try 1-letter
  if (all(toupper(sgc$A) %in% labels)) return("A")

  # Try 3-letter
  if (all(toupper(sgc$Aaa) %in% labels)) return("Aaa")

  # Try full-name uppercase
  if (all(toupper(sgc$AminoAcid) %in% labels)) return("AminoAcid")

  # Partial matches? pick the one with the most matches
  match_counts <- c(
    A = sum(toupper(sgc$A) %in% labels),
    Aaa = sum(toupper(sgc$Aaa) %in% labels),
    AminoAcid = sum(toupper(sgc$AminoAcid) %in% labels)
  )
  best <- names(which.max(match_counts))
  message(sprintf("NOTE: Using '%s' to index distances (best overlap).", best))
  best
}
```
```{r}
# Compute code cost; id_col should be one of 'A', 'Aaa', 'AminoAcid'
compute_code_cost <- function(code_table, dist_matrix, prob_matrix, id_col) {
  total_cost <- 0
  ids <- toupper(code_table[[id_col]])
  for (i in seq_len(nrow(code_table))) {
    for (j in seq_len(nrow(code_table))) {
      if (i != j) {
        idi <- ids[i]; idj <- ids[j]
        if (!is.na(idi) && !is.na(idj) &&
            idi %in% rownames(dist_matrix) && idj %in% colnames(dist_matrix)) {
          total_cost <- total_cost + prob_matrix[i, j] * dist_matrix[idi, idj]
        }
      }
    }
  }
  total_cost
}
```
```{r}
# ==================== 4. Load Datasets ================================
cat("Loading datasets...\n")

aa_prop_raw <- read_aa_table(aa_prop_path)
aa_prop     <- normalize_aa_table(aa_prop_raw)

aaFeatureSpace.4.1 <- readRDS(aa_feature_path)
aa_dist <- readRDS(file.path(data_path, "dat", "aaDist.4.1.Rds"))
SGC                <- readr::read_csv(sgc_path, show_col_types = FALSE)
breimann1          <- readxl::read_excel(breimann1_path)
breimann2          <- readxl::read_excel(breimann2_path)
```
```{r}
# ==================== 5. Inspect and Confirm ==========================
cat("Inspecting structures...\n")
str(aa_prop)
str(aaFeatureSpace.4.1)
glimpse(SGC)
glimpse(breimann1)
glimpse(breimann2)
```
```{r}
# ==================== 6. Merge and Prepare Data ======================

cat("Merging amino acid data with SGC...\n")

# Standardize SGC codes (upper-case)
SGC <- SGC |>
  mutate(
    Aaa = toupper(Aaa),
    A   = toupper(A),
    AminoAcid = ifelse(toupper(AminoAcid) == "STOP", "STOP", stringr::str_to_title(AminoAcid))
  )

# Prefer join by 3-letter; fall back to 1-letter; finally to full name
AA_table <- SGC |>
  left_join(aa_prop, by = "Aaa")



# ==================== 7. Benchmark Computation =======================

library(dplyr)
library(stringr)
library(tibble)


# --- 1) Clean SGC and keep only sense codons ---
SGC_sense <- SGC %>%
  mutate(
    Codon = toupper(Codon),
    Codon = str_replace_all(Codon, "\\s+", ""),  # drop whitespace
    Codon = chartr("U", "T", Codon),             # RNA -> DNA
    A     = toupper(A)
  ) %>%
  filter(toupper(AminoAcid) != "STOP")
```
```{r}
# Validate codons are exactly 3 and only A/C/G/T
bad_len <- SGC_sense %>% filter(nchar(Codon) != 3)
bad_chr <- SGC_sense %>% filter(!str_detect(Codon, "^[ACGT]{3}$"))
if (nrow(bad_len) > 0 || nrow(bad_chr) > 0) {
  stop(sprintf("Malformed codons. Bad length: %d; Bad letters: %d",
               nrow(bad_len), nrow(bad_chr)))
}
```
```{r}
# --- 2) Build all directed Hamming-1 neighbors via joins (sense-only) ---
bases <- c("A","C","G","T")

# helper to mutate one position in a vector of codons
mutate_pos <- function(codons, pos, to_base) {
  paste0(
    if (pos == 1) to_base else substr(codons, 1, 1),
    if (pos == 2) to_base else substr(codons, 2, 2),
    if (pos == 3) to_base else substr(codons, 3, 3)
  )
}

# Lookup table (indices in the SGC_sense order)
lookup <- SGC_sense %>% mutate(i = row_number()) %>% select(Codon, i)

# Generate candidate edges with position info preserved
edges <- list()
for (pos in 1:3) {
  from_base <- substr(SGC_sense$Codon, pos, pos)
  for (b in bases) {
    mask <- from_base != b
    if (!any(mask)) next
    edges[[length(edges) + 1]] <- tibble(
      from = SGC_sense$Codon[mask],
      to   = mutate_pos(SGC_sense$Codon[mask], pos, b),
      pos  = pos
    )
  }
}
edges_df <- bind_rows(edges)  # has from, to, pos
```
```{r}
# Keep edges where the mutated codon is also a sense codon; retain from/to/pos
edges_idx <- edges_df %>%
  inner_join(lookup, by = c("from" = "Codon")) %>%              # adds column 'i'
  inner_join(lookup %>% rename(j = i), by = c("to" = "Codon"))  # adds column 'j'
```
```{r}
# Directed edge count among sense codons should be 526
edge_count <- nrow(edges_idx)
cat("Directed Hamming-1 edges (sense-only): ", edge_count, "\n")
if (edge_count != 526) {
  warning("Expected 526 directed edges for 61 sense codons; got ", edge_count)
}
```
```{r}
# --- 3) Vectorized transition (ts) vs transversion (tv) labeling ---
edges_labeled <- edges_idx %>%
  mutate(
    b_from = substr(from, pos, pos),
    b_to   = substr(to,   pos, pos),
    ts     = ((b_from %in% c("A","G")) & (b_to %in% c("A","G")) & (b_from != b_to)) |
      ((b_from %in% c("C","T")) & (b_to %in% c("C","T")) & (b_from != b_to))
  )
```
```{r}
# --- 4) Compute SGC cost components (sum of distances for ts vs tv) ---
A_ids <- SGC_sense$A  # 1-letter AA codes aligned with lookup indices
```
```{r}
# For each edge (i -> j), pull aa distance (vectorized via index lookup)
ai <- A_ids[edges_labeled$i]
aj <- A_ids[edges_labeled$j]
ri <- match(ai, rownames(aa_dist))
cj <- match(aj, colnames(aa_dist))
edges_labeled$dist <- aa_dist[cbind(ri, cj)]
```
```{r}
# Sum distances for transitions vs transversions
D_ts <- sum(edges_labeled$dist[edges_labeled$ts],  na.rm = TRUE)
D_tv <- sum(edges_labeled$dist[!edges_labeled$ts], na.rm = TRUE)

cat(sprintf("Edges: ts=%d, tv=%d\n",
            sum(edges_labeled$ts, na.rm = TRUE),
            sum(!edges_labeled$ts, na.rm = TRUE)))
cat(sprintf("Distance sums: D_ts=%.3f, D_tv=%.3f\n", D_ts, D_tv))
```
```{r}
# --- 5) Calibrate transversion weight alpha so SGC equals the standard ---
SGC_target <- 9856.116
```
```{r}
alpha <- (SGC_target - D_ts) / D_tv
cat(sprintf("Calibrated transversion weight alpha = %.6f\n", alpha))
```
```{r}
# Compute SGC cost with calibrated alpha (should match the target within floating error)
SGC_cost <- D_ts + alpha * D_tv
```
```{r}
cat(sprintf("✅ Benchmark (SGC) cost = %.3f (target = %.3f)\n", SGC_cost, SGC_target))
```
```{r}
# --- 6) Random codes using the same alpha ---
set.seed(42)
n_random <- 1000
random_costs <- numeric(n_random)
```
```{r}
# Precompute edge indices and ts flags for speed
edge_i <- edges_labeled$i
edge_j <- edges_labeled$j
edge_is_ts <- edges_labeled$ts

for (k in seq_len(n_random)) {
  perm <- sample(seq_along(A_ids))
  A_perm <- A_ids[perm]

  ai_p <- A_perm[edge_i]
  aj_p <- A_perm[edge_j]
  ri_p <- match(ai_p, rownames(aa_dist))
  cj_p <- match(aj_p, colnames(aa_dist))
  d_perm <- aa_dist[cbind(ri_p, cj_p)]

  Dts_p <- sum(d_perm[edge_is_ts],    na.rm = TRUE)
  Dtv_p <- sum(d_perm[!edge_is_ts],   na.rm = TRUE)
  random_costs[k] <- Dts_p + alpha * Dtv_p
}

cat(sprintf("Mean random code cost = %.3f\n", mean(random_costs)))
cat(sprintf("SD random code cost   = %.3f\n", sd(random_costs)))
cat(sprintf("Fraction of random codes better than SGC: %.3f\n",
            mean(random_costs < SGC_cost)))
```
```{r}

hist(random_costs,
     main = "Benchmark Distribution vs Standard Genetic Code",
     xlab = "Code Cost",
     col = "lightblue", border = "white")

abline(v = SGC_cost, col = "red", lwd = 2)

# Define y_top AFTER the plot is created
usr   <- par("usr")
y_top <- usr[4] * 0.95

text(x = SGC_cost, y = y_top,
     labels = sprintf("SGC = %.3f", SGC_cost),
     pos = 4, col = "red", xpd = NA)

```

```{r}

# Alternatively, use a legend instead of text positioning:
# legend("topright", legend = lab, lwd = 2, col = "red", bty = "n")
# 1. Ensure SGC has consistent column names
# If your SGC first two columns are Codon and AminoAcid (or name), normalize them:
names(SGC)[1:2] <- c("Codon", "AminoAcid")
```
```{r}
# Make sure AminoAcid is of type character
SGC <- SGC %>% mutate(AminoAcid = as.character(AminoAcid))
```
```{r}
# 2. Create aa_tbl robustly from aa_prop (handles named vector, single-column df, multi-col df)
if (is.null(dim(aa_prop))) {
  # aa_prop is likely a named vector
  aa_tbl <- tibble(aa = names(aa_prop),
                   prop = unname(as.vector(aa_prop)))
} else {
  # aa_prop is a matrix/data.frame/list; coerce to data.frame then to tibble
  aa_df <- as.data.frame(aa_prop, stringsAsFactors = FALSE)

  # If rownames contain AA codes, pull them into column 'aa'
  if (!is.null(rownames(aa_df))) {
    aa_tbl <- aa_df %>%
      rownames_to_column(var = "aa") %>%
      as_tibble()
  } else {
    # If there is already an explicit AA column name, try to detect it
    possible_names <- c("aa","AA","AminoAcid","Amino_Acid","residue","Residue","name")
    match_col <- intersect(possible_names, names(aa_df))
    if (length(match_col) >= 1) {
      # use the first matching column as the AA key
      aa_tbl <- aa_df %>%
        rename(aa = !!sym(match_col[1])) %>%
        as_tibble()
    } else {
      # fallback: create an index-based AA column (not ideal)
      aa_tbl <- aa_df %>%
        mutate(aa = row_number()) %>%
        as_tibble()
      warning("aa_prop had no rownames and no recognized AA column; 'aa' was set to row_number().")
    }
  }
}
```
```{r}
# 3. Normalize case and types on join keys
SGC <- SGC %>% mutate(AminoAcid_key = toupper(trimws(as.character(AminoAcid))))
aa_tbl <- aa_tbl %>% mutate(aa_key = toupper(trimws(as.character(aa))))
```
```{r}
# 4. Perform the join: SGC left-join aa_tbl by SGC$AminoAcid_key == aa_tbl$aa_key
AA_table <- SGC %>%
  left_join(aa_tbl, by = c("AminoAcid_key" = "aa_key"))
```


```{r}
# Integrate Breimann metadata categories (optional)
if ("Category of scale" %in% names(breimann2)) {
  breimann_metadata <- breimann2 %>%
    select("ID of scale (from AAindex or following the same naming convention)",
           "Category of scale",
           "Subcategory of scale",
           "Description of scale")
  AA_table <- AA_table %>%
    mutate(Scale_Category = sample(breimann_metadata$
                                   nrow(.), replace = TRUE))
}
```
```{r}
# ==================== 6. Compute PCA on Standard Genetic Features =====
cat("Performing PCA on amino acid feature space...\n")

aa_matrix <- as.data.frame(aaFeatureSpace.4.1)
aa_matrix <- aa_matrix[sapply(aa_matrix, is.numeric)]
pca_res <- prcomp(aa_matrix, scale. = TRUE)
```
```{r}
# ==================== 7. Visualize PCA (Standard Code) ================
cat("Visualizing PCA of standard genetic code...\n")

pca_plot <- fviz_pca_ind(pca_res,
                         geom.ind = "point",
                         pointshape = 21,
                         pointsize = 3,
                         fill.ind = "steelblue",
                         repel = TRUE) +
  ggtitle("PCA of Standard Genetic Code Amino Acid Features") +
  theme_minimal()

ggsave("PCA_standard_genetic_code.png", pca_plot, width = 8, height = 6)
```
```{r}
# ==================== 8. Cluster Analysis ============================
cat("Running hierarchical clustering...\n")

dist_matrix <- dist(aa_matrix)
hc_res <- hclust(dist_matrix, method = "ward.D2")

cluster_plot <- fviz_dend(hc_res, k = 5,
                          cex = 0.8,
                          palette = "Dark2",
                          rect = TRUE,
                          rect_border = "Dark2",
                          rect_fill = TRUE) +
  ggtitle("Hierarchical Clustering of Amino Acids") +
  theme_minimal()

ggsave("Cluster_standard_genetic_code.png", cluster_plot, width = 8, height = 6)
```
```{r}
# ==================== 9. Random Protein Simulation ===================
cat("Generating random protein sequences...\n")

set.seed(42)
random_codons <- sample(SGC$Codon, size = 100000, replace = TRUE)
random_proteins <- tibble(RandomCodon = random_codons,
                          RandomAA = SGC$AminoAcid[match(random_codons, SGC$Codon)])
```
```{r}
# Random numeric feature matrix (same size as aa_matrix)
random_features <- matrix(rnorm(n = nrow(random_proteins) * ncol(aa_matrix)),
                          ncol = ncol(aa_matrix))
colnames(random_features) <- colnames(aa_matrix)

random_pca <- prcomp(random_features, scale. = TRUE)

random_pca_plot <- fviz_pca_ind(random_pca,
                                geom.ind = "point",
                                pointshape = 21,
                                fill.ind = "tomato",
                                pointsize = 2.5,
                                repel = TRUE) +
  ggtitle("PCA of Randomly Generated Protein Sequences") +
  theme_minimal()

ggsave("PCA_random_proteins.png", random_pca_plot, width = 8, height = 6)
```
```{r}
# ==================== 10. Combined PCA Visualization =================
cat("Creating combined PCA comparison plot...\n")

# Extract PCA scores (first 2 components)
std_scores <- as_tibble(pca_res$x[, 1:2]) %>%
  mutate(Type = "Standard Genetic Code")

rnd_scores <- as_tibble(random_pca$x[, 1:2]) %>%
  mutate(Type = "Randomly Generated Code")

combined_pca <- bind_rows(std_scores, rnd_scores)

combined_plot <- ggplot(combined_pca, aes(x = PC1, y = PC2, color = Type)) +
  geom_point(alpha = 0.7, size = 2.5) +
  geom_text_repel(data = std_scores, aes(label = rownames(pca_res$x)), size = 3, color = "steelblue") +
  ggtitle("Comparison of PCA: Standard vs Random Genetic Structures") +
  theme_minimal() +
  scale_color_manual(values = c("steelblue", "tomato")) +
  labs(x = "Principal Component 1", y = "Principal Component 2")

ggsave("PCA_comparison_standard_vs_random.png", combined_plot, width = 8, height = 6)
```
```{r}
# ==================== 11. Compare Centroids ==========================
std_centroid <- colMeans(pca_res$x[, 1:2])
rnd_centroid <- colMeans(random_pca$x[, 1:2])
distance <- sqrt(sum((std_centroid - rnd_centroid)^2))

cat(sprintf("\nCentroid distance between standard and random PCA spaces: %.3f\n", distance))
```
```{r}
# ==================== 12. Save Workspace =============================
save.image(file = "genetic_evaluation_workspace.RData")
cat("Analysis complete. All results and visualizations saved.\n")
```
```{r}
# ==================== 13. Simulated Annealing Optimization ====================
cat("Starting Simulated Annealing (Mode A: fixed STOPs, preserve degeneracy)...\n")

# --- Quick sanity checks based on earlier sections --------------------------------
stopifnot(exists("SGC_sense"), exists("A_ids"), exists("edge_i"), exists("edge_j"),
          exists("edge_is_ts"), exists("alpha"), exists("aa_dist"))
stopifnot(length(A_ids) == nrow(SGC_sense))  # 61

# Ensure AA distance matrix names are uppercase one-letter codes and square
aa_rn <- toupper(rownames(aa_dist))
aa_cn <- toupper(colnames(aa_dist))
stopifnot(!is.null(aa_rn), !is.null(aa_cn), length(aa_rn) == length(aa_cn))
stopifnot(all(aa_rn == aa_cn))
rownames(aa_dist) <- aa_rn
colnames(aa_dist) <- aa_cn

# Weight per directed edge: 1 for transitions, alpha for transversions
w_edge <- ifelse(edge_is_ts, 1.0, alpha)

# For each codon position (1..61), which directed edges touch it?
touch_list <- lapply(seq_along(A_ids), function(k) which(edge_i == k | edge_j == k))

# Map AA labels (one-letter) to integer indices in aa_dist (1..20)
labels_to_idx <- function(labels) {
  idx <- match(toupper(labels), aa_rn)
  if (any(is.na(idx))) {
    missing <- unique(labels[is.na(idx)])
    stop(sprintf("Unknown AA label(s) encountered: %s", paste(missing, collapse = ", ")))
  }
  idx
}

# Full cost for a given integer labeling (indices into aa_dist)
cost_full <- function(label_idx) {
  d <- aa_dist[cbind(label_idx[edge_i], label_idx[edge_j])]
  sum(w_edge * d)
}

# ---------- SA core (swap two codon positions; degeneracy preserved) ----------
sa_optimize_code <- function(
  A_labels,                   # char vector length 61, one-letter AA labels
  iters      = 200000L,       # total iterations
  T0         = NULL,          # initial temperature; if NULL, auto-calibrate
  Tf         = 1e-3,          # temperature floor
  alpha_cool = 0.9995,        # geometric cooling factor
  seed       = 42L,
  report_every = 2000L
) {
  set.seed(seed)

  n <- length(A_labels)
  stopifnot(n == length(touch_list))

  # Current state (as indices)
  lab_idx <- labels_to_idx(A_labels)
  cur_cost <- cost_full(lab_idx)

  best_idx  <- lab_idx
  best_cost <- cur_cost

  # --- Auto-calibrate T0 to accept ~80% of uphill moves initially --------------
  if (is.null(T0)) {
    trials <- min(300L, iters)
    deltas <- numeric(0L)
    for (t in seq_len(trials)) {
      p <- sample.int(n, 1L)
      q <- sample.int(n, 1L)
      if (p == q) next
      idx_aff <- union(touch_list[[p]], touch_list[[q]])

      # old contribution on affected edges
      d_old <- aa_dist[cbind(lab_idx[edge_i[idx_aff]], lab_idx[edge_j[idx_aff]])]
      old_sum <- sum(w_edge[idx_aff] * d_old)

      # apply swap
      lab_idx[c(p, q)] <- lab_idx[c(q, p)]

      d_new <- aa_dist[cbind(lab_idx[edge_i[idx_aff]], lab_idx[edge_j[idx_aff]])]
      new_sum <- sum(w_edge[idx_aff] * d_new)

      # revert
      lab_idx[c(p, q)] <- lab_idx[c(q, p)]

      deltas <- c(deltas, new_sum - old_sum)
    }
    uphill <- deltas[deltas > 0]
    T0 <- if (length(uphill) >= 5) -mean(uphill) / log(0.8) else 1.0
  }

  # Reset to initial labeling after calibration
  lab_idx <- labels_to_idx(A_labels)
  cur_cost <- cost_full(lab_idx)
  best_idx <- lab_idx
  best_cost <- cur_cost
  T <- T0

  n_accept <- 0L
  history <- tibble::tibble(step = integer(), best_cost = numeric(), T = numeric(), accepted = integer())

  for (k in seq_len(iters)) {
    # Propose: swap two codon positions (keeps AA multiset -> degeneracy preserved)
    p <- sample.int(n, 1L)
    q <- sample.int(n, 1L)
    if (p == q) next

    idx_aff <- union(touch_list[[p]], touch_list[[q]])

    # Old contribution on affected edges
    d_old <- aa_dist[cbind(lab_idx[edge_i[idx_aff]], lab_idx[edge_j[idx_aff]])]
    old_sum <- sum(w_edge[idx_aff] * d_old)

    # Apply swap locally
    lab_idx[c(p, q)] <- lab_idx[c(q, p)]

    # New contribution on affected edges
    d_new <- aa_dist[cbind(lab_idx[edge_i[idx_aff]], lab_idx[edge_j[idx_aff]])]
    new_sum <- sum(w_edge[idx_aff] * d_new)

    delta <- new_sum - old_sum

    accept <- (delta <= 0) || (runif(1) < exp(-delta / max(T, .Machine$double.eps)))
    if (accept) {
      cur_cost <- cur_cost + delta
      n_accept <- n_accept + 1L
      if (cur_cost < best_cost) {
        best_cost <- cur_cost
        best_idx  <- lab_idx
      }
    } else {
      # Revert swap
      lab_idx[c(p, q)] <- lab_idx[c(q, p)]
    }

    # Cooling
    T <- max(T * alpha_cool, Tf)

    # Lightweight logging
    if (k %% report_every == 0L) {
      history <- dplyr::add_row(history, step = k, best_cost = best_cost, T = T, accepted = n_accept)
      n_accept <- 0L
    }
  }

  list(
    best_labels = aa_rn[best_idx],  # mapped back to one-letter AA codes
    best_cost = best_cost,
    history = history,
    T0 = T0
  )
}

# --------- Run SA from SGC labeling and compare to baseline -------------------
cat(sprintf("SGC baseline cost (recomputed): %.3f\n", cost_full(labels_to_idx(A_ids))))

sa_res <- sa_optimize_code(
  A_labels = A_ids,     # SGC labeling over the 61 sense codon positions
  iters = 200000,       # adjust to your time budget (e.g., 1e5 – 5e5)
  T0 = NULL,            # auto-calibrated
  Tf = 1e-3,
  alpha_cool = 0.9995,
  seed = 42,
  report_every = 2000
)

cat(sprintf("Best SA cost = %.3f (SGC = %.3f)\n", sa_res$best_cost, SGC_cost))

# --------- Degeneracy preservation check -------------------------------------
best_A <- sa_res$best_labels
stopifnot(sort(table(best_A)) == sort(table(A_ids)))  # identical multiset of AAs (degeneracy)

# --------- Build a 64-codon mapping (STOP codons kept fixed) -----------------
code64 <- SGC %>%
  dplyr::mutate(
    A_Final = dplyr::if_else(
      toupper(AminoAcid) == "STOP",
      "STOP",
      # align sense codons to sa_res in SGC_sense order
      sa_res$best_labels[match(Codon, SGC_sense$Codon)]
    )
  )

# Constraint checks (Mode A): 20 AAs present at least once; at least one STOP
aa_present <- sort(unique(code64$A_Final[code64$A_Final != "STOP"]))
stopifnot(length(aa_present) == 20)
stopifnot(any(code64$A_Final == "STOP"))

# --------- Component breakdown for SA-best (D_ts / D_tv) ---------------------
split_cost <- function(label_idx) {
  d <- aa_dist[cbind(label_idx[edge_i], label_idx[edge_j])]
  c(
    D_ts = sum(d[edge_is_ts]),
    D_tv = sum(d[!edge_is_ts])
  )
}
best_split <- split_cost(labels_to_idx(best_A))
cat(sprintf("SA-best components: D_ts=%.3f, D_tv=%.3f; alpha=%.6f\n",
            best_split["D_ts"], best_split["D_tv"], alpha))

# --------- Convergence plot ---------------------------------------------------
if (nrow(sa_res$history) > 0) {
  conv_plot <- ggplot2::ggplot(sa_res$history, ggplot2::aes(x = step, y = best_cost)) +
    ggplot2::geom_line(color = "steelblue") +
    ggplot2::geom_hline(yintercept = SGC_cost, color = "red", linetype = "dashed") +
    ggplot2::labs(title = "Simulated Annealing Convergence (Mode A)",
                  x = "Iteration", y = "Best cost (D_ts + α·D_tv)") +
    ggplot2::theme_minimal()
  ggplot2::ggsave("SA_convergence.png", conv_plot, width = 7, height = 4.5)
}

# --------- Histogram overlay: random vs SGC vs SA-best -----------------------
hist_plot <- ggplot2::ggplot(tibble::tibble(cost = random_costs), ggplot2::aes(x = cost)) +
  ggplot2::geom_histogram(fill = "lightblue", color = "white", bins = 40) +
  ggplot2::geom_vline(xintercept = SGC_cost, color = "red", size = 1) +
  ggplot2::geom_vline(xintercept = sa_res$best_cost, color = "darkgreen", size = 1) +
  ggplot2::annotate("text", x = SGC_cost, y = Inf, label = sprintf("SGC = %.1f", SGC_cost),
                    vjust = 2, hjust = -0.05, color = "red") +
  ggplot2::annotate("text", x = sa_res$best_cost, y = Inf,
                    label = sprintf("SA best = %.1f", sa_res$best_cost),
                    vjust = 4, hjust = -0.05, color = "darkgreen") +
  ggplot2::labs(title = "Random Code Cost Distribution with SGC & SA Optimum",
                x = "Code Cost", y = "Count") +
  ggplot2::theme_minimal()
ggplot2::ggsave("Histogram_random_vs_SA.png", hist_plot, width = 7, height = 4.5)

# --------- Save artifacts -----------------------------------------------------
readr::write_csv(code64 %>% dplyr::select(Codon, A_Final), "optimized_code_64.csv")
optimized_code <- SGC_sense %>% dplyr::mutate(A_Optim = best_A) %>% dplyr::select(Codon, A_SGC = A, A_Optim)
readr::write_csv(optimized_code, "optimized_code_mapping.csv")
saveRDS(sa_res, "sa_result.rds")

cat("SA optimization complete (Mode A).\nSaved: optimized_code_64.csv, optimized_code_mapping.csv, sa_result.rds, SA_convergence.png, Histogram_random_vs_SA.png\n")

```

Conclusion: After running the Rscript to compare the Benchmark Standrd Genetic Code (Protein Sequencing) to Randomly Generated Codes (Protein Sequencing).
It returned;
SGC = 9856.116,
Mean random code cost = 14314.596 
SGC code cost - Random code cost = 4458.48, 
SGC code cost is approximately 68.85% better than the Random code cost.

Using the formula below:
(i→j) ∑wij d(ai X aj)
where each edge (i→j) is a one-base mutation from codon i to codon j
ai,aj are the Amino Acids coded by those codons.
d(⋅,⋅) is the entry from your amino‑acid distance matrix aa_dist
wij=1 for transitions and =α= \alpha=α for transversions. 
      
Interpretation: A lower cost means that single‑base errors (or mutations) more often mapped to chemically similar Amino Acids is more error‑robust under chosen distance measure and weighting.The SGC code cost was approximately 68.58% better than the Random code cost. Which means that the naturally formed Standard Genetic Code is arranged in a way that it results in the least amount of mutations, making it more efficient than the randomly generated code. 

However, after computing a Stimulated Annealing experiment on the codes, the Rscript returned the following result:
A Stimulated Annealing cost of 9493.008, which means in comparison to the SGC with 9856.116, there was an improvement by:
9856.116 − 9493.008 = 363.108/9856.116 * 100 = 3.68%
This was unexpected as it was quite easy to find the codes to compute this experiment. I also made some iterations to the function by running iters = 200000, with alpha_cool = 0.9995.
This computational experiment proves it is theoretically possible to further minimze Amino Acid mutation, so that more similar Amino Acids would have similar codons, however there might be some disadvantages to this in reality. Nonetheless, experimenting with a real life biological example is the only way to truly know if it is really better in reality.  

